{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-01 11:55:12.892580: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-01 11:55:12.933989: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-01 11:55:13.680543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import \"aataset\" (is in upper folder)\n",
    "import dataset\n",
    "import models\n",
    "import config\n",
    "from torch import nn\n",
    "# import summary\n",
    "import torch\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 513, 431])\n"
     ]
    }
   ],
   "source": [
    "# get a sample from the dataset\n",
    "dataloader = dataset.get_dataloader()\n",
    "spectrogram, caption = next(iter(dataloader))\n",
    "spectrogram = spectrogram.to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 128, 107])\n"
     ]
    }
   ],
   "source": [
    "# run spectrogram through vae encoder\n",
    "vae = models.VAE()\n",
    "\n",
    "encodings_real = vae.encode(spectrogram)\n",
    "encodings_real = encodings_real.latent_dist.mode()\n",
    "# print shape\n",
    "print(encodings_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 128, 107])\n"
     ]
    }
   ],
   "source": [
    "# generate a fake sample\n",
    "ngpu = torch.cuda.device_count()\n",
    "# Create the generator\n",
    "netG = models.Generator(vae, ngpu).to(config.DEVICE)\n",
    "\n",
    "# Handle multi-GPU if desired\n",
    "if (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "#  to ``mean=0``, ``stdev=0.02``.\n",
    "netG.apply(models._weights_init)\n",
    "\n",
    "# apply the model to the fixed noise\n",
    "fake = netG(config.FIXED_NOISE).detach().cpu()\n",
    "# print the shape\n",
    "print(fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 64, 64, 54]           4,608\n",
      "       BatchNorm2d-2            [1, 64, 64, 54]             128\n",
      "         LeakyReLU-3            [1, 64, 64, 54]               0\n",
      "            Conv2d-4           [1, 128, 32, 27]          73,728\n",
      "       BatchNorm2d-5           [1, 128, 32, 27]             256\n",
      "         LeakyReLU-6           [1, 128, 32, 27]               0\n",
      "            Conv2d-7           [1, 256, 16, 14]         294,912\n",
      "       BatchNorm2d-8           [1, 256, 16, 14]             512\n",
      "         LeakyReLU-9           [1, 256, 16, 14]               0\n",
      "           Conv2d-10               [1, 1, 8, 7]           2,304\n",
      "          Sigmoid-11               [1, 1, 8, 7]               0\n",
      "          Flatten-12                    [1, 56]               0\n",
      "           Linear-13                     [1, 1]              57\n",
      "          Sigmoid-14                     [1, 1]               0\n",
      "================================================================\n",
      "Total params: 376,505\n",
      "Trainable params: 376,505\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.42\n",
      "Forward/backward pass size (MB): 8.91\n",
      "Params size (MB): 1.44\n",
      "Estimated Total Size (MB): 10.76\n",
      "----------------------------------------------------------------\n",
      "Number of trainable parameters: 376505\n"
     ]
    }
   ],
   "source": [
    "# now, the summary of the netd\n",
    "# Create the Discriminator\n",
    "netD = models.Discriminator(ngpu).to(config.DEVICE)\n",
    "\n",
    "# Handle multi-GPU if desired\n",
    "if (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "# like this: ``to mean=0, stdev=0.2``.\n",
    "netD.apply(models._weights_init)\n",
    "\n",
    "# Print the model\n",
    "summary(netD, (8, 128, 107), 1)\n",
    "print(f\"Number of trainable parameters: {sum(p.numel() for p in netD.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real result: tensor([[0.4088]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "Fake result: tensor([[0.3835]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# run the real and fake data through the discriminator\n",
    "real_result = netD(encodings_real)\n",
    "fake_result = netD(fake)\n",
    "\n",
    "# print the results\n",
    "print(f\"Real result: {real_result}\")\n",
    "print(f\"Fake result: {fake_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
