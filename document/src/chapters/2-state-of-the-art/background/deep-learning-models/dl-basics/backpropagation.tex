\paragraph{Backpropagation Algorithm for Training Neural Networks} \label{sec:backpropagation}

\textit{Backpropagation} is an algorithm used to train feedforward neural networks by computing the gradient of the loss function concerning the network weights. This gradient is then used to update the weights in the opposite direction of the gradient, allowing the network to learn how to predict outputs given inputs accurately.

To understand backpropagation, it is crucial to define the loss function, which measures the network's performance on a given task. For instance, the cross-entropy loss is commonly used in classification tasks to quantify the difference between predicted probabilities and the correct labels. More information on loss functions can be found in Section \ref{sec:loss-functions}. Backpropagation adjusts the network weights to minimize the loss function.

The backpropagation algorithm works by computing the gradient of the loss function concerning each weight in the network. This gradient tells how much the loss function would change if one were to make a small change to the weight. This gradient is then used to update the weight in the direction that reduces the loss function.

The gradient is computed using the chain rule of calculus. Considering a simple feedforward neural network with one hidden layer. The output of the network is given by:

\begin{equation}
	y = h(\sum_{j=1}^M w_{2,j} h(\sum_{i=1}^N w_{1,i} x_i + b_1) + b_2)
\end{equation}

where $x_i$ is the $i$-th input, $w_{1, i}$ and $w_{2, j}$ are the weights connecting the input to the hidden layer and the hidden layer to the output, respectively, $b_1$ and $b_2$ are the biases of the hidden layer and the output, respectively, $h$ is the activation function, such as sigmoid, (see section \ref{sec:activation}), and $N$ and $M$ are the numbers of inputs and hidden units, respectively.

The loss function is a function of the output $y$ and the actual label $t$.

To compute the gradient of the loss function concerning a weight $w_{i,j}$, one first needs to compute the local gradient of the output for the weight. This is given by:

\begin{equation}
	\frac{\partial y}{\partial w_{i,j}} = h'(\sum_{j=1}^M w_{2,j} h(\sum_{i=1}^N w_{1,i} x_i + b_1) + b_2) h(\sum_{i=1}^N w_{1,i} x_i + b_1) w_{2,j}
\end{equation}

where $h'$ is the derivative of the activation function. One can then use the chain rule to compute the gradient of the loss function for the weight:

\begin{equation}
	\frac{\partial E}{\partial w_{i,j}} = (y - t)\frac{\partial y}{\partial w_{i,j}}
\end{equation}

Once one has computed the gradient of the loss function concerning all the weights in the network, the weights can be updated using gradient descent:

\begin{equation}
	w_{i,j} \leftarrow w_{i,j} - \alpha \frac{\partial E}{\partial w_{i,j}}
\end{equation}

where $\alpha$ is the learning rate, which determines the step size of the weight update.

Backpropagation can be extended to networks with multiple hidden layers using the chain rule to propagate the gradient backward through the network.