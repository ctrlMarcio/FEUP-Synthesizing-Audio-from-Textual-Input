\subsubsection{Foundations of Deep Learning} \label{sec:dl-foundations}

This section explores the fundamental principles of \ac{DL}, with a specific focus on activation functions and backpropagation. Activation functions play a vital role in neural networks by introducing non-linearity and enabling the representation of complex relationships. This section covers the most commonly used activation functions. In addition, this section discusses the backpropagation algorithm, which plays a crucial role in training feedforward neural networks by calculating gradients with respect to network weights for iterative adjustments and optimal model performance. Furthermore, this section explores optimization techniques within deep learning.

\input{src/chapters/2-state-of-the-art/background/deep-learning-models/dl-basics/activation}
\input{src/chapters/2-state-of-the-art/background/deep-learning-models/dl-basics/backpropagation}
\input{src/chapters/2-state-of-the-art/background/deep-learning-models/dl-basics/sgd}
\input{src/chapters/2-state-of-the-art/background/deep-learning-models/dl-basics/adam}