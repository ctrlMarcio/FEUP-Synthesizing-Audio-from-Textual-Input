\chapter{Conclusions} \label{chap:concl}

\minitoc

The field of \ac{DL} and audio has witnessed the emergence of generative \ac{AI} models for audio synthesis, a challenging and fascinating research topic. This thesis has investigated the evolution and evaluation of these models, with the main objectives of understanding the current state of the art and creating a novel model using a generative approach. To achieve these goals, this thesis has followed a comprehensive methodology that included conducting a literature review and developing and evaluating a generative \ac{AI} model for audio synthesis.

This chapter concludes the thesis by presenting the main results and contributions of the research. It also reflects on the research process and methodology, and suggests future directions for further research.

The first section, Section~\ref{sec:reflection-goals}, of this chapter provides an overview of the research goals that guided the investigation into the development and evaluation of generative \ac{AI} models for audio synthesis. Section~\ref{sec:reflection-process} reflects on the research process and methodology employed throughout the research, highlighting the strengths and limitations of the chosen approach, and discussing the challenges and lessons learned during the development of the \ac{AI} models. The third section, \ref{sec:future-directions}, outlines potential areas of future work that can help advance the field of generative \ac{AI} models for audio synthesis, addressing some of the open questions and limitations identified in the research.

\section{Overview of Research Goals} \label{sec:reflection-goals}

This section presents an overview of the research goals that directed the examination into the evolution and evaluation of generative \ac{AI} models for audio synthesis.

The two research goals can be summarized as follows: to understand the current state of the art in generative \ac{DL} and audio, and to create one of these models.

\subsection{Comprehensive Study of State-of-the-Art Deep Learning Architectures and Models for Audio Synthesis}

Throughout the thesis, a comprehensive study of the current state-of-the-art deep learning architectures for audio synthesis was conducted, including \acp{GAN}, \acp{VAE}, diffusion models, and other related architectures. This study included an in-depth analysis of the strengths, limitations, and potential applications of these architectures in the context of audio synthesis.

In addition, various models that use these deep learning architectures were examined, such as VALL-E, AudioGen, AudioLM, and others. Each model was thoroughly analyzed to understand their unique approaches, techniques, and contributions to audio synthesis. The results of this study provided valuable insights into the different models and their effectiveness in producing high-quality audio.

Extensive research was also conducted to examine previous algorithms used for sound processing, including techniques for augmentation, feature extraction, and other purposes. This research involved a thorough review of existing algorithms and their applicability to audio generative models. The insights gained from this research were used in the development of practical systems and contributed to the overall understanding of sound processing techniques in the context of generative AI models.

This work culminated in a thorough state-of-the-art chapter (Chapter~\ref{chap:sota}), which provides a comprehensive overview of current advances in deep learning architectures and models for audio synthesis. The chapter presents a detailed analysis of the studied architectures and models, highlighting their strengths, limitations, and potential applications.

In addition, the findings and insights from this research have been summarized in a review paper that has been submitted to a prestigious journal for peer review. This review paper aims to provide a comprehensive and up-to-date overview of the state of the art in deep learning architectures and models for audio synthesis. It is currently awaiting approval and publication in the journal.

\subsection{Developing End-to-End Systems for Sound Synthesis and Evaluation}

The goal of developing end-to-end systems for sound synthesis from text input has been partially achieved. While initial prototypes have been created, the results have not been satisfactory due to limitations in the available datasets and the lack of hyperparameter fine-tuning in the models. However, the potential for improvement is significant, and future work proposed in the conclusion suggests new models that could yield better results.

The goal of evaluating the ability of systems to generate sound from textual input remains an ongoing challenge. Finding and testing robust evaluation functions is a complex task that requires further research and dedicated effort. Due to time constraints, this objective has not been fully completed, and only a comparison using the loss function of \ac{GAN} has been performed. 

In summary, the research objectives outlined in this dissertation have been addressed to varying degrees. A comprehensive study of \ac{DL} architectures and prior sound processing algorithms has been conducted. The development of end-to-end systems for sound synthesis from text input has shown promising progress, while the evaluation of their accuracy remains an ongoing challenge. These achievements contribute to the existing knowledge and understanding of audio generative models and pave the way for future research and development in this area.

\section{Reflection on the Research Process} \label{sec:reflection-process}

Throughout this research, a comprehensive methodology was employed to ensure the successful achievement of the research objectives. The chosen methodology is presented in Section~\ref{sec:sol-approach} and involved conducting a thorough review of the state of the art while simultaneously initiating the writing process. This iterative and agile approach allowed for continuous refinement of ideas and incorporation of the latest developments in the field.

Reflecting on the effectiveness of the chosen methodology, it can be concluded that it successfully guided the research process. The methodology provided a structured framework for conducting the research and ensured that the objectives were addressed in a systematic and efficient manner. The challenges encountered during the research process were not related to the methodology itself, but rather to the complexity of the chosen research topic.

One challenge encountered during the research process was the sometimes tedious and frustrating nature of developing \ac{AI} models. Troubleshooting problems during training required additional time and effort, often requiring extended training periods to evaluate potential solutions. However, these challenges provided valuable lessons in patience, problem solving, and the importance of careful experimentation.


\section{Future Directions} \label{sec:future-directions}

The study and development of generative \ac{AI} models for audio synthesis have shown promising results in producing realistic and diverse audio output. However, there are still several avenues for further exploration and improvement. This section outlines potential areas of future work that can help advance the field of generative \ac{AI} models for audio synthesis.

\subsection{Exploring Novel Architectures}

The objective of this section is to recommend new frameworks that expand upon the groundwork established in this thesis. Developing these suggested frameworks is deferred to future research due to limited time and resources.

The proposed theoretical methods presented in this Section are motivated by the necessity of increasing the quality, diversity, and efficacy of the produced audio.

This section outlines the objectives, design principles, and possible applications of each suggested architecture. Furthermore, it discusses the methodological considerations and potential obstacles that may arise during their development and implementation.

It is essential to note that the proposed theoretical approaches presented here are intended to serve as a basis for future research. Researchers and practitioners are encouraged to explore, refine, and contribute to the advancement of generative \ac{AI} models for audio synthesis.

This section provides detailed explanations of each proposed architecture, including insights into its design principles, implementation considerations, and potential applications. This approach aims to stimulate further exploration and innovation in the field.

\input{src/chapters/5-conclusion/theoretical/VAMOS}
\input{src/chapters/5-conclusion/theoretical/stable-diffusion}
\input{src/chapters/5-conclusion/theoretical/theoretical-model}

\subsection{Dataset Expansion}

Expanding the available datasets plays a critical role in training generative \ac{AI} models for audio synthesis. Larger and more diverse datasets provide models with a broader understanding of audio patterns, leading to more realistic and varied audio synthesis. In this subsection, we explore various strategies for dataset expansion, including the incorporation of new data augmentation techniques and the creation of new datasets through real-world recordings and crowdsourcing.

Data augmentation techniques are essential for increasing the diversity and size of the dataset. In the context of audio synthesis, several state-of-the-art data augmentation techniques have been proposed. These techniques can be seen in Section~\ref{sec:data-augmentation} and include time stretching, pitch shifting, noise injection, and others. By applying these techniques, one can artificially introduce variation into the dataset, allowing the models to learn from a wider range of audio patterns.

In future work, it is important to investigate the effectiveness of these data augmentation techniques in the context of audio synthesis. Specifically, the impact of each technique on the performance and generalization of generative models should be evaluated. This evaluation can be done by conducting systematic experiments that compare the performance of models trained with and without data augmentation. In addition, it would be valuable to investigate the combination of multiple data augmentation techniques to further increase the diversity and quality of the dataset.

Furthermore, the exploration of novel data augmentation techniques specifically tailored to audio data should be considered. This may involve exploring and adapting techniques from other domains, such as image or text data augmentation, and tailoring them to the unique characteristics of audio data. The development of domain-specific data augmentation techniques can potentially open up new possibilities for improving the realism and variety of audio synthesis.

Expanding the dataset may also involve creating new datasets that capture a broader range of audio characteristics. One approach is to include real-world recordings, such as live performances, field recordings, or professional studio recordings. These recordings provide a more realistic training environment for the models because they capture the nuances and complexities of real-world audio. Collaborating with musicians, audio engineers, or other experts in the field can ensure the acquisition of high-quality and diverse audio recordings.

Crowdsourcing provides an opportunity to expand the dataset by incorporating user-generated content from online platforms or social media. This approach allows for the inclusion of a diverse and constantly evolving dataset that reflects current trends and preferences in audio production. However, crowdsourced datasets come with their own challenges, such as ensuring data quality and addressing potential biases. Careful curation and validation processes should be implemented to maintain the integrity of the dataset.

\subsection{Evaluation Metrics}

Accurately evaluating the performance of generative \ac{AI} models' performance is challenging. Existing evaluation metrics often fail to capture the quality, variety, and realism of the generated audio. Future work should focus on developing robust evaluation metrics that align with human perception and subjective audio quality. By establishing reliable evaluation metrics, one can objectively evaluate and compare the performance of different models, facilitating advancements in the field.

As the dataset expands, it becomes necessary to develop new evaluation metrics that can assess the quality and diversity of the dataset. Existing evaluation metrics used in the field may have limitations in capturing the richness and diversity of the expanded datasets. Therefore, exploring and proposing new evaluation metrics that can effectively measure the performance and capabilities of generative models trained on the expanded datasets is important. These metrics should consider factors such as audio realism, diversity of generated outputs, and alignment with ground truth data.

By addressing these areas of future work, the scientific community can further advance the capabilities of generative \ac{AI} models for audio synthesis. Exploring novel architectures, expanding datasets, and developing improved evaluation metrics will contribute to the development of more powerful and reliable models, enabling applications in diverse domains such as music production, sound design, and interactive audio experiences.

\section{Conclusion} \label{sec:conc-conc}

In summary, this chapter has presented the conclusive results of an extensive investigation into the study and advancement of generative \ac{AI} models. The primary objectives of this research have been largely achieved, with the identification and discussion of the obstacles that prevented the full achievement of all objectives.

In addition, this study has significantly contributed to the existing body of knowledge on generative \ac{DL}. While developing end-to-end systems for sound synthesis from textual input remains arduous, particularly for researchers not affiliated with prominent technology companies, this thesis has made notable progress in this area. Initial prototypes have been developed, albeit with unsatisfactory results due to limitations in available datasets and the need for meticulous fine-tuning of hyper-parameters. Nevertheless, the potential for further improvement is recognized. Evaluating the ability of systems to generate sound from textual input also remains an ongoing challenge that warrants further investigation and refinement.

In conclusion, this research has provided invaluable insights into the study and development of generative \ac{AI}, focusing on audio synthesis. It has successfully achieved significant milestones, conducted a comprehensive investigation of \ac{DL} architectures and models, and made notable progress in creating end-to-end systems for sound synthesis.