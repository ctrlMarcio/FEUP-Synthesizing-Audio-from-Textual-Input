\subsubsection{PixelCNN Decoders} \label{sec:pixelcnn}

Van den Oord et al. introduced \textit{PixelCNNs} as discussed in \cite{oord_conditional_2016, van_den_oord_pixel_2016}. PixelCNNs model high-dimensional discrete data, like images.

They employ the \ac{AE} architecture as described in Section \ref{sec:darn}, where pixels are generated sequently while conditioning on prior pixels.

The goal is to estimate a distribution over images that can be used to compute the likelihood of images and thus generate new ones. The network scans the image one row at a time and one pixel at a time within each row, using masked convolutions (see Section~\ref{sec:masked-conv}). For each pixel, it predicts the conditional distribution over the possible pixel values given the scanned context.

Each image $x$ is assigned a probability $p(x)$. To do this, if one considers each pixel sequentially, row by row, such that $x_k$ is the pixel number $k$, the final probability is as follows.

\begin{equation}
    p(x) = \prod_{i=1}^{h \times w} p(x_i | x_1, \dots, x_{i-1})
\end{equation}

Where $h$ is the height of the image and $w$ is the width.

For multiple colors, one can condition the colors on one another. For instance, instead of having $x_1$, $x_2$, \dots, there would be $x_1^R$, $x_1^G$, $x_1^B$, $x_2^R$, and so forth.