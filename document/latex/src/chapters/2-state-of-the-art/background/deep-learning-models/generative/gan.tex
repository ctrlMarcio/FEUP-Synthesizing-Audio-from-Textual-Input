\paragraph{Generative Adversarial Network (GAN)} \label{sec:gan}

The paper ``Generative Adversarial Networks'' by Goodfellow et al. \cite{goodfellow_generative_2014} introduced a novel framework for generative modeling using deep neural networks. The main idea behind \acp{GAN} is to train two neural networks simultaneously, one generator and one discriminator.

By transforming a random noise vector $z$ into a target distribution in some data space $\hat{X}$ (for example, spectrograms), the generator network $G$ produces new samples. Meanwhile, the discriminator $D$ attempts to tell apart synthetic and real data; that is, $D$ assigns the input data, whether it is $X$ or $\hat{X}$, a categorical label based on whether it believes the input originated from the actual data distribution $p(X)$ or the model distribution $p(z)$. Figure \ref{fig:gan} shows this process.


\begin{figure}[ht]
    \centering
    \ctikzfig{figures/2-sota/gan}
    \caption[Generative adversarial network]{\textbf{\Acf{GAN}} --- A random noise vector $\vec{z}$ is passed through the generator in $G(\vec{z})$ to create the synthetic sample $\hat{X}$. Both this and the real sample $X$ are passed to the discriminator $D$ that predicts which of the samples is the real one. It is important to notice that in this illustration, the circles represent entire neural networks and not simply neurons.}
    \label{fig:gan}
\end{figure}

Using a minimax optimization framework, the networks are trained in an adversarial way. The goal is that $G$ generates a fake sample $\hat{X}$ that is given to $D$ along with a real one $X$. This network then has to identify which is genuine and which is fabricated. $D$ is trained to increase the probability of telling apart the real from the fake data. While $G$ is trained at the same time for the opposite objective, that is, to deceive $D$ by minimizing $\log(1 - D(G(z)))$ \cite{huzaifah_deep_2021}. $G$ and $D$ are trained in turns until a Nash equilibrium is achieved.

When $G$ creates flawless fake data that cannot be told apart from real data, a Nash equilibrium is reached. $D$ has no clue whether the data is real or fake and just makes random guesses about the input label. In this situation, $G$ performs at its best, and $D$ performs at its worst. The models cannot get any better than this. This is a perfect scenario that requires effort to attain in reality. It is worth noting that the generator never sees the training samples, only the feedback given by the discriminator \cite{huzaifah_deep_2021}.

Once the training is done, the discriminator is thrown away, and the generator can be used to draw samples from the learned distribution of the real data. The generator has learned to associate random vectors with data samples in the target domain. These vectors usually represent some features. As a result, they cluster output data with similar features to nearby input values, offering a natural way of exploring output data with different attributes. This implies that similar input vectors will produce similar outputs \cite{huzaifah_deep_2021}.

Although this technique has seen great success in producing high-resolution images, it still needs to improve in the audio domain as the sections in Section~\ref{sec:related-work} show. Besides that, even in ideal settings, it has some drawbacks. For instance, the fact that the training of the whole model implies the training of two different networks makes it unstable. It is easy to get stuck at a sub-optimal nash equilibrium. One such example is mode collapse, where the generator produces limited variations of the target distribution.

\Acfp{DARN} (see Section \ref{sec:darn}) represented the state-of-the-art in neural audio synthesis for a long time. These models are good at learning local latent structure, this is, the features of sounds over brief periods. However, they struggle with longer-term features. Besides, \acp{DARN} are very slow because they generate waveforms one sample at a time. \Acp{GAN} are capable of modeling global latent structure since they build the output as a whole; moreover, after training, they generate way faster \cite{tahiroglu_-terity_2020}, showing promising features for audio generation.