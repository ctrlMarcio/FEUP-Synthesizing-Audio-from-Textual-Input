\chapter{GANmix Implementation Details} \label{ann:ganmix-implementation}

\section{Model Implementation}

\begin{lstlisting}[language=Python, caption={Implementation of the GANmix model.}]
class GANMix():

    # ... (initialization code)

    @classmethod
    def build(cls):
        latents_shape = (8, 128, 107)

        num_workers = torch.cuda.device_count()

        vae = models.VAE()

        netG = Generator(config.GENERATOR_INPUT_SIZE, 200, latents_shape)
        netD = Discriminator(latents_shape, 200, config.GAUSSIAN_NOISE)

        # ... (parallelization and GPU)

        criterion = BCEWithLogitsLoss()

        optimizerD = optim.Adam(netD.parameters(
        ), lr=config.LEARNING_RATE_DISCRIMINATOR, betas=(config.BETA1, 0.999))
        optimizerG = optim.Adam(netG.parameters(
        ), lr=config.LEARNING_RATE_GENERATOR, betas=(config.BETA1, 0.999))

        return cls(vae, netG, netD, optimizerG, optimizerD, criterion, num_workers)

class Generator(nn.Module):

    # ... (initialization)

    def forward(self, x):
        x = x.to(config.DEVICE)

        x = self.network(x)

        return x

    def _build_network(self):
        network = nn.Sequential(
            nn.Linear(self.input_size, self.hidden_size),
            nn.LeakyReLU(0.2),
            nn.Linear(self.hidden_size, np.prod(self.output_shape)),
        )
        return network

    def forward(self, x):
        x = x.to(config.DEVICE)

        x = self.network(x)
        x = x.view(-1, *self.output_shape)

        return x

class Discriminator(nn.Module):

    # ... (initialization)

    def forward(self, x):
        x = x + torch.randn_like(x) * self.gaussian_noise_std

        x = self.network(x)

        return x

    def _build_network(self):
        network = nn.Sequential(
            nn.Flatten(),
            nn.Linear(np.prod(self.input_shape), self.hidden_size),
            nn.LeakyReLU(0.2),
            nn.Linear(self.hidden_size, 1),
            nn.Tanh()
        )
        return network
\end{lstlisting}

The GANmix model is a \ac{GAN} that combines a \ac{VAE} to generate realistic audio from latent vectors.

\subsection{VAE}
The \ac{VAE} is a neural network that encodes an input spectrogram into a latent vector and then decodes it back into an output spectrogram.

The \ac{VAE} used in this model is AudioLDM's~\cite{liu_audioldm_2023} \ac{VAE}, which is already trained. It has an encoder and a decoder, both of which are \acp{CNN} with residue blocks. The encoder outputs two vectors: the latent vector's mean and logarithmic variance. The decoder takes a latent vector as input and outputs an image.

\subsection{Generator}
The generator is a neural network that inputs a latent vector and outputs a set of embeddings corresponding to the \ac{VAE} embedding space. The generator is trained to fool the discriminator into believing that the generated embeddings are real.

The generator used in GANmix is implemented by the class \texttt{Generator}. The generator has three attributes: \texttt{input\_size}, \texttt{hidden\_size}, and \texttt{output\_shape}. The \texttt{input\_size} is the dimension of the latent vector, which is stored in the config file and is 100 (this and all values can be seen in the appendix ~\ref{ann:ganmix-conf}. The \texttt{hidden\_size} is the dimension of the hidden layer, which in this case is 200. The \texttt{output\_shape} is the shape of the embeddings, in this case $(8, 128, 107)$.

The generator has a method called \texttt{\_build\_network()} that returns a sequential network consisting of three layers: a linear layer, a leaky \ac{ReLU} activation function, and another linear layer. The first linear layer maps the input vector to the hidden layer. The second linear layer maps the hidden layer to the output vector, which has the same size as the product of the output form.

The generator also has a \texttt{forward()} method that takes an input vector \texttt{x} and passes it through the network. It then transforms the output vector into the shape of the \ac{VAE} embedding space.

\subsection{Discriminator}

The discriminator is a neural network that takes a set of embeddings as input and outputs a value indicating how real or fake the image is. The discriminator is trained to distinguish between real embeddings from the \ac{VAE} and fake embeddings from the generator. The discriminator can also be used to evaluate how realistic the generated embeddings are by calculating their scores.

The discriminator used in this thesis is implemented using the class \texttt{Discriminator}. The discriminator has three attributes: \texttt{input\_shape}, \texttt{hidden\_size}, and \texttt{gaussian\_noise\_std}. The \texttt{input\_shape} is the shape of the input embeddings. The \texttt{hidden\_size} is the size of the hidden layer. The \texttt{gaussian\_noise\_std} is the standard deviation of the Gaussian noise added to the input image, which in this case is $0.1$, no fine-tuning was performed.

The discriminator has a method called \texttt{\_build\_network()} that returns a sequential network consisting of five layers: a flatten layer, a linear layer, a leaky \ac{ReLU} activation function, another linear layer, and a tanh activation function. The flatten layer flattens the input image into a vector. The first linear layer maps the input vector to the hidden layer. The second linear layer maps the hidden layer to the output scalar.

The discriminator also has a method called \texttt{forward()}, which takes an input image \texttt{x} and adds Gaussian noise with standard deviation \texttt{gaussian\_noise\_std} to it. Then, it passes it through the network and returns the output scalar.

\subsection{GANMix}

The GANMix class is a wrapper class that contains all of these models. Plus the loss criterion and optimizers

\section{Training Implementation}

\begin{lstlisting}[language=Python, caption={Implementation of the training loop for the GANmix.}]
# ... (initialization)

def _gen_fake_samples(generator, num_samples):
    noise = torch.randn(num_samples, config.GENERATOR_INPUT_SIZE, device=config.DEVICE)
    fake_samples = generator(noise)
    return fake_samples

def _embed_samples(vae, samples):
    embeddings = vae.encode(samples)
    embeddings = embeddings.latent_dist.mode()
    embeddings = torch.nan_to_num(embeddings, nan=0)
    return embeddings

def _train_discriminator(data, ganmix, settings):
    with autocast():
        real_data = data.to(config.DEVICE)
        batch_size = real_data.size(0)

        real_embeddings = _embed_samples(ganmix.vae, real_data)

        fake_embeddings = _gen_fake_samples(ganmix.generator, batch_size)

        ganmix.discriminator_optimizer.zero_grad()

        prediction_real = ganmix.discriminator(real_embeddings)
        prediction_fake = ganmix.discriminator(fake_embeddings.detach())

        real_label = torch.ones(batch_size, 1, device=config.DEVICE)
        fake_label = -torch.ones(batch_size, 1, device=config.DEVICE)

        loss_real = ganmix.criterion(prediction_real, real_label)
        loss_fake = ganmix.criterion(prediction_fake, fake_label)

        loss_discriminator = loss_real + loss_fake

    settings.scaler.scale(loss_discriminator).backward()
    settings.scaler.step(ganmix.discriminator_optimizer)
    settings.scaler.update()

    return loss_discriminator

def _train_generator(ganmix, settings):
    with autocast():

        fake_data = _gen_fake_samples(ganmix.generator, config.BATCH_SIZE)

        ganmix.generator_optimizer.zero_grad()

        prediction_fake = ganmix.discriminator(fake_data)

        fake_label = torch.ones(config.BATCH_SIZE, 1, device=config.DEVICE)

        loss_generator = ganmix.criterion(prediction_fake, fake_label)

    settings.scaler.scale(loss_generator).backward()
    settings.scaler.step(ganmix.generator_optimizer)
    settings.scaler.update()

    return loss_generator


# ... (output and display)


def run_train():

    # ... (initialization)

    with open(settings.stats_file_path, 'a', newline='') as csvfile:

        # ... (display options)

        for epoch in range(config.NUM_EPOCHS):
            loss_discriminator_list = []
            loss_generator_list = []

            for data, quote in tqdm(settings.dataloader):
                loss_discriminator = _train_discriminator(data, ganmix, settings)
                loss_discriminator_list.append(loss_discriminator.item())

                loss_generator = _train_generator(ganmix, settings)
                loss_generator_list.append(loss_generator.item())

            _output_epoch_results(settings.start_time, epoch, ganmix.generator, ganmix.vae, loss_discriminator_list, loss_generator_list, csv_writer, csvfile)

def main():
    run_train()
\end{lstlisting}

Training of the GANmix model is implemented using the \texttt{run\_train()} and \texttt{main()} functions. Training involves several steps: data loading, model building, loss calculation, optimization, and output display.

\subsection{Data Loading}

The data loading step is responsible for loading the dataset of audios and quotes and creating a data loader that iterates over the data batches. The data set and the data loader are stored in the \texttt{settings} object, which is an instance of the \texttt{Settings} class. The \texttt{Settings} class is defined in another module and contains various parameters and paths for the training.

The data loader is created using PyTorch's \texttt{torch.utils.data.DataLoader} class. The data loader takes the data set as an argument and returns batches of data with a specified batch size. The batch size used in this model was 8. The data loader also shuffles the data and supports multiprocessing.

\subsection{Model Building}

The model build step is responsible for creating an instance of the \texttt{GANMix} model and moving it to the \ac{GPU}, if available.

\subsection{Loss Calculation}

The loss computation step is responsible for computing the losses for the generator and the discriminator using the criterion and the predictions from the model.

The loss calculation consists of two sub-steps: generating and embedding dummy samples.

\subsubsection{Generate Dummy Samples}

The generate dummy samples substep generates dummy embeddings from random latent vectors using the generator.

This sub-step is implemented using the \texttt{\_gen\_fake\_samples()} function, which takes the generator and the number of samples to generate as arguments and returns the dummy images as a tensor.

The \texttt{\_gen\_fake\_samples()} function performs the following steps:

\begin{enumerate}
    \item Sample random latent vectors from a standard normal distribution using PyTorch's \texttt{torch.rand()} function.
    \item Generate dummy images from the latent vectors using the generator's \texttt{forward()} method.
\end{enumerate}

\subsubsection{Embedding Samples}

The embedding samples sub-step is responsible for embedding real spectrograms into latent vectors using the \ac{VAE}'s encoder.

This sub-step is implemented using the \texttt{\_embed\_samples()} function, which takes the \ac{VAE} and the samples to embed as arguments and returns the latent vectors as a tensor.

The \texttt{\_embed\_samples()} function performs the following steps:

\begin{enumerate}
    \item Encodes the samples using the \texttt{encode()} method of the \ac{VAE}.
    \item Extract the mode of the latent vector from the \texttt{latent\_dist} attribute.
\end{enumerate}

The loss computation step also consists of two main steps: training the discriminator and training the generator.

\subsubsection{Discriminator Training}

The discriminator training step is responsible for updating the discriminator parameters using the discriminator optimizer and the discriminator loss. The discriminator loss is calculated by comparing the discriminator predictions for the real and fake emails with the real and fake labels.

The discriminator training step is implemented using the \texttt{\_train\_discriminator()} function, which takes the data, the ganmix model, and the settings object as arguments and returns the discriminator loss as a scalar.

The \texttt{\_train\_discriminator()} function performs the following steps:

\begin{enumerate}
    \item Move the real data to the \ac{GPU} using the \texttt{to()} method.
    \item Get the batch size from the real data using the \texttt{size()} method.
    \item Embed the real data into latent vectors using the \texttt{\_embed\_samples()} function.
    \item Generate fake embeddings from random latent vectors using the \texttt{\_gen\_fake\_samples()} function.
    \item Compute the discriminator predictions for the real and fake embeddings using the discriminator's \texttt{forward()} method.
    \item Compute the discriminator losses for the real and fake predictions using the criterion's \texttt{forward()} method.
    \item Compute the total discriminator loss by adding the real and fake losses.
\end{enumerate}

\subsubsection{Training the Generator}

The generator training step updates the generator parameters using the generator optimizer and the generator loss. The generator loss is calculated by comparing the discriminator predictions for the fake images with the real labels.

The generator training step is implemented using the \texttt{\_train\_generator()} function, which takes the ganmix model and the settings object as arguments and returns the generator loss.

The \texttt{\_train\_generator()} function performs the following steps:

\begin{enumerate}
    \item Generate fake data from random latent vectors using the \texttt{\_gen\_fake\_samples()} function.
    \item Compute discriminator predictions for the fake data using the discriminator's \texttt{forward()} method.
    \item Generate the real labels using PyTorch's \texttt{torch.ones()} function.
    \item Compute the generator loss by comparing the fake predictions and the real labels using the criterion's \texttt{forward()} method.
\end{enumerate}

\subsection{Training Loop}


For the specified number of epochs, the program analyzes the entire data set, first training the discriminator and then training the generator. The corresponding losses for both are noted and displayed by the program.