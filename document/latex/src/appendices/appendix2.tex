\chapter{GAN Implementation Details} \label{ann:GAN}

\section{Models}

\subsection{Generator}

The generator model is constructed as a sequential neural network. Its goal is to take a noise input and generate audio samples that resemble the desired output.

\begin{lstlisting}[language=Python, caption={Generator initialization}]
def _make_generator_model(self, input_shape=(100,)):
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Dense(
        256, use_bias=False, input_shape=input_shape))
    model.add(tf.keras.layers.Reshape((16, 16)))
    model.add(tf.keras.layers.ReLU())
    model.add(tf.keras.layers.Conv1DTranspose(
        32, 25, strides=4, padding='same'))
    model.add(tf.keras.layers.ReLU())
    model.add(tf.keras.layers.Conv1DTranspose(
        16, 25, strides=4, padding='same'))
    model.add(tf.keras.layers.ReLU())
    model.add(tf.keras.layers.Conv1DTranspose(
        8, 25, strides=4, padding='same'))
    model.add(tf.keras.layers.ReLU())
    model.add(tf.keras.layers.Conv1DTranspose(
        4, 25, strides=4, padding='same'))
    model.add(tf.keras.layers.ReLU())
    model.add(tf.keras.layers.Conv1DTranspose(
        2, 25, strides=4, padding='same'))
    model.add(tf.keras.layers.ReLU())
    model.add(tf.keras.layers.Conv1DTranspose(
        1, 25, strides=4, padding='same'))
    model.add(tf.keras.layers.Activation('tanh'))

    return model
\end{lstlisting}

The generator consists of 6 blocks, each of which consists of a transposed convolution layer followed by a \ac{ReLU} activation function (see Sections~\ref{sec:transpoed-conv} and~\ref{sec:relu}). The exception is the last block, which uses a \ac{tanh} activation function (explained in Sections~\ref{sec:tanh}) to ensure that the generated audio values fall within the range of -1 to 1.

\subsection{Discriminator}

The discriminator model is designed to distinguish between real and generated audio samples. Like the generator, it's implemented as a sequential neural network.

\begin{lstlisting}[language=Python, caption={Discriminator initialization}]
def _make_discriminator_model(self, input_shape=(INPUT_SIZE, 1)):
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Conv1D(1, 25, strides=4,
                                     input_shape=input_shape, padding='same'))
    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))

    model.add(tf.keras.layers.Conv1D(2, 25, strides=4, padding='same'))
    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))

    model.add(tf.keras.layers.Conv1D(4, 25, strides=4, padding='same'))
    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))

    model.add(tf.keras.layers.Conv1D(8, 25, strides=4, padding='same'))
    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))

    model.add(tf.keras.layers.Conv1D(16, 25, strides=4, padding='same'))
    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))

    model.add(tf.keras.layers.Conv1D(32, 25, strides=4, padding='same'))
    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))

    model.add(tf.keras.layers.Flatten())

    model.add(tf.keras.layers.Dense(1))

    return model
\end{lstlisting}

The discriminator consists of 6 convolutional blocks, each followed by a leaky \ac{ReLU} activation function. After these blocks, the model is flattened to be fed into a dense layer with a single output unit to provide a binary classification indicating whether the input is real or generated.

\section{Training}

The \ac{GAN} training procedure involves a series of steps to iteratively optimize the generator and discriminator networks.

\begin{lstlisting}[language=Python, caption={Training operations}]
def train(self, dataset, epochs):
    # ... (checkpoint loading operations)

    # run the epochs
    for epoch in tqdm(range(epochs)):
        print("Epoch {}/{}".format(epoch+1, epochs))

        # run the batches
        for audios in tqdm(dataset):
            self._train_step(audios)

        # ... (display and checkpoint operations)

@tf.function
def _train_step(self, audios):
    noise = tf.random.normal([BATCH_SIZE, self._fake_input_shape[0]])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_audios = self._generator(noise, training=True)

        real_output = self._discriminator(audios, training=True)
        fake_output = self._discriminator(generated_audios, training=True)

        gen_loss = self._generator_loss(fake_output)
        disc_loss = self._discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(
        gen_loss, self._generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(
        disc_loss, self._discriminator.trainable_variables)

    self._generator_optimizer.apply_gradients(
        zip(gradients_of_generator, self._generator.trainable_variables))
    self._discriminator_optimizer.apply_gradients(
        zip(gradients_of_discriminator, self._discriminator.trainable_variables))

def _generator_loss(self, fake_output):
    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output)

def _discriminator_loss(self, real_output, fake_output):
    real_loss = tf.keras.losses.BinaryCrossentropy(
        from_logits=True)(tf.ones_like(real_output), real_output)
    fake_loss = tf.keras.losses.BinaryCrossentropy(
        from_logits=True)(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss
\end{lstlisting}

For each epoch, the generator produces a set of generated audio samples using random noise. Both the real and generated audio samples are then passed through the discriminator network to calculate their respective outputs.

The generator and discriminator losses are calculated based on the discriminator outputs. The generator aims to minimize the \ac{BCE} loss associated with the output of the fake samples, thereby encouraging the discriminator to classify them as real. Conversely, the discriminator seeks to minimize the loss by discriminating between real and false samples.

The gradients of the generator and discriminator losses are computed using a gradient band, and the model parameters are updated accordingly using the Adam optimizer (see Section~\ref{sec:adam}).