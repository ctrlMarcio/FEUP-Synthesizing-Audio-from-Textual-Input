\section{Development}

\subsection{Datasets}

\begin{frame}
    \frametitle{Table of Datasets}

    \begin{table}[ht]
        \centering
        \caption{Comparison of datasets for soundscapes}
        \label{tab:datasets}
        \begin{tabularx}{\textwidth}{|X|X|X|X|X|}
            \hline
            \textbf{Name}                                     &
            \textbf{Type}                                     &
            \textbf{\# Samples}                               &
            \textbf{Duration}                                 &
            \textbf{Labels}                                     \\ \hline

            Acoustic Event Dataset \cite{takahashi_deep_2016} &
            Categorical labeled                               &
            5223                                              &
            Average 8.8s                                      &
            One of 28 labels                                    \\ \hline

            AudioCaps \cite{kim_audiocaps_2019}               &
            Descriptive labeled                               &
            39597                                             &
            10s each                                          &
            9 words per caption                                 \\ \hline

            AudioSet \cite{gemmeke_audio_2017}                &
            Categorical labeled                               &
            2084320                                           &
            Average 10s                                       &
            One or more of 527 labels                           \\ \hline

            Audio MNIST~\cite{becker_interpreting_2018}       &
            Categorical labeled                               &
            30000                                             &
            Average 0.6s                                      &
            One of 10 labels                                    \\ \hline
        \end{tabularx}
    \end{table}
\end{frame}

\begin{frame}
    \frametitle{Table of Datasets (contd.)}

    \begin{table}[ht]
        \centering
        \caption{Comparison of datasets for soundscapes (contd.)}
        \begin{tabularx}{\textwidth}{|X|X|X|X|X|}
            \hline
            \textbf{Name}                                           &
            \textbf{Type}                                           &
            \textbf{\# Samples}                                     &
            \textbf{Duration}                                       &
            \textbf{Labels}                                           \\ \hline

            Clotho \cite{drossos_clotho_2019}                       &
            Descriptive labeled                                     &
            4981                                                    &
            15 to 30s                                               &
            24 905 captions (5 per audio).                            \\ \hline

            FSDKaggle 2018 \cite{fonseca_general-purpose_2018}      &
            Categorical labeled                                     &
            11073                                                   &
            From 300ms to 30s                                       &
            One or more of 41 labels                                  \\ \hline

            Urban Sound 8K \cite{salamon_dataset_2014}              &
            Categorical labeled                                     &
            8732                                                    &
            Less or equal to 4s                                     &
            One of 10 labels                                          \\ \hline

            YouTube-8M Segments \cite{abu-el-haija_youtube-8m_2016} &
            Categorical labeled                                     &
            237000                                                  &
            5s                                                      &
            One or more of 1000 labels                                \\ \hline
        \end{tabularx}
    \end{table}
\end{frame}


\subsection{Exploratory Experiments}

\begin{frame}
    \frametitle{Exploratory Experiments}

    \begin{itemize}
        \item Objective: Gain insights for GANmix development
        \item Experiments: Classification, GAN, AE, VAE
        \item Findings: Foundation for audio representation, GAN effectiveness, AE/VAE capabilities
        \item Impact: Crucial for robust audio generation with GANmix
    \end{itemize}

\end{frame}

\subsection{GANmix}

\begin{frame}{GANmix}

    \begin{figure}
        \centering
        \includegraphics[height=0.8\textheight]{images/3-development/ganmix.pdf}
        \caption{GANmix architecture}
        \label{fig:ganmix}
    \end{figure}

    \note{
        \textbf{Introduction}
        \begin{itemize}
            \item GANmix: Fusion of GAN and VAE for audio generation under constraints.
            \item Addresses computational limitations for high-quality audio.
            \item Combines GAN's generative power with VAE's latent space manipulation.
        \end{itemize}

        \textbf{Model Architecture}
        \begin{itemize}
            \item Generator and discriminator operate in latent space.
            \item VAE Training: Computational challenge, requires extensive datasets.
            \item AudioLDM's High-Performance: Top model for audio generation.
            \item Accessibility of AudioLDM: Open source, accessible via Hugging Face's model hub.
        \end{itemize}

        \textbf{Early Results}
        \begin{itemize}
            \item Preliminary experiments with Audio MNIST: Promising but suboptimal.
            \item Refinements: Different optimizers, model sizes, loss functions.
            \item Clotho dataset: Significant improvement in generated audio quality.
            \item Challenges in achieving equilibrium between generator and discriminator.
        \end{itemize}

        \textbf{Final Model}
        \begin{itemize}
            \item GANmix architecture with Clotho dataset: Significant improvements.
            \item Unlike typical models using CNN, GANmix uses fully connected neural networks.
            \item Generator input: Random Gaussian noise, passes through hidden layers.
            \item Discriminator: Takes embedding as input, applies tanh activation.
            \item Loss function: BCE. Optimized with Adam. Learning rate updates every 10 epochs.
        \end{itemize}
    }
\end{frame}
